# ML Pipeline Finalization Summary

## ‚úÖ Completed Components

### 1Ô∏è‚É£ **data_processing.py**

**Location:** `src/data_processing.py`

**Required Functions:**
- ‚úÖ `load_data()` - Loads raw transaction data from CSV
- ‚úÖ `aggregate_customer_features()` - Aggregates transaction-level data to customer-level features
- ‚úÖ `preprocessing_pipeline()` - Creates sklearn Pipeline with ColumnTransformer for data preprocessing

**Key Features:**
- Uses `sklearn.pipeline.Pipeline` for composable transformations
- Implements `StandardScaler` for numeric features
- Handles missing values with `SimpleImputer`
- Supports optional categorical encoding with `OneHotEncoder`

---

### 2Ô∏è‚É£ **rfm.py**

**Location:** `src/rfm.py`

**Required Functions:**
- ‚úÖ `calculate_rfm()` - Calculates Recency, Frequency, and Monetary features
- ‚úÖ `create_proxy_target()` - Creates proxy risk labels using clustering

**Key Features:**
- **Recency:** Days since last transaction (lower = more active)
- **Frequency:** Total number of transactions per customer
- **Monetary:** Total amount spent by customer
- Uses `StandardScaler` to normalize RFM features before clustering
- Uses `KMeans(n_clusters=3, random_state=42)` for customer segmentation
- Automatically identifies high-risk cluster (highest average recency)

---

### 3Ô∏è‚É£ **train.py**

**Location:** `src/train.py`

**Required Functions:**
- ‚úÖ `run_training_pipeline()` - Complete end-to-end training pipeline

**Key Features:**
- Uses `train_test_split` (80/20 split, stratified)
- Trains **LogisticRegression** model
- Trains **RandomForestClassifier** model
- Evaluates both models using **ROC-AUC** metric
- Saves models using **joblib**

---

## üéØ MLflow Integration

### What MLflow Logs:

#### **Parameters Logged:**
- `raw_data_rows` - Number of rows in raw data
- `raw_data_cols` - Number of columns in raw data
- `n_customers` - Total unique customers
- `n_clusters` - Number of clusters (3)
- `test_size` - Train/test split ratio (0.2)
- `random_state` - Random seed for reproducibility (42)
- `train_samples` - Number of training samples
- `test_samples` - Number of test samples
- `lr_max_iter` - Logistic Regression max iterations
- `rf_n_estimators` - Random Forest number of trees
- `rf_max_depth` - Random Forest max depth
- `best_model` - Name of best performing model

#### **Metrics Logged:**
- `class_0_count` - Number of low-risk customers
- `class_1_count` - Number of high-risk customers
- `class_imbalance_ratio` - Ratio of high-risk to low-risk
- `lr_roc_auc` - Logistic Regression ROC-AUC score
- `rf_roc_auc` - Random Forest ROC-AUC score
- `best_model_roc_auc` - Best model's ROC-AUC score
- `feature_importance_*` - Feature importances (if Random Forest is best)

#### **Model Artifacts Logged:**
- `models/logistic_regression_model.pkl` - Logistic Regression model
- `models/random_forest_model.pkl` - Random Forest model
- `models/preprocessor.pkl` - Preprocessing pipeline
- `best_model/` - Best performing model (MLflow format)
- `preprocessor/` - Preprocessor (MLflow format)

#### **Registered Models:**
- `credit_risk_randomforest` or `credit_risk_logisticregression` - Best model
- `credit_risk_preprocessor` - Preprocessing pipeline

---

## üìä Pipeline Execution Flow

```
1. Load Raw Data (data_processing.load_data)
   ‚Üì
2. Calculate RFM Features (rfm.calculate_rfm)
   ‚Üì
3. Create Proxy Risk Labels (rfm.create_proxy_target)
   ‚Üì
4. Split Train/Test Data (train_test_split)
   ‚Üì
5. Preprocess Features (preprocessing_pipeline)
   ‚Üì
6. Train Models (LogisticRegression + RandomForestClassifier)
   ‚Üì
7. Evaluate ROC-AUC
   ‚Üì
8. Log to MLflow (Parameters, Metrics, Artifacts)
   ‚Üì
9. Save Models (joblib + MLflow)
```

---

## üöÄ How to Run the Pipeline

### Command:
```bash
python -m src.train
```

### Expected Output:
```
--- Loading Raw Data ---
--- Engineering RFM Features & Proxy Target ---
Proxy Target Created. Risk Cluster ID: X
--- Splitting Data ---
--- Preprocessing ---
--- Training Models ---

[1/2] Training Logistic Regression...
‚úì Logistic Regression ROC-AUC: X.XXXX

[2/2] Training Random Forest...
‚úì Random Forest ROC-AUC: X.XXXX

============================================================
PERFORMANCE METRICS (ROC-AUC)
============================================================
Logistic Regression ROC-AUC: X.XXXX
Random Forest ROC-AUC:       X.XXXX
============================================================

üèÜ Best Model: [ModelName] (ROC-AUC: X.XXXX)

--- Saving Artifacts ---
‚úì Models saved to 'models/' directory
‚úì Artifacts logged to MLflow

‚úÖ Training pipeline completed successfully!
MLflow Run ID: [run_id]
```

---

## üìÅ Generated Artifacts

### In `models/` directory:
- `logistic_regression_model.pkl`
- `random_forest_model.pkl`
- `preprocessor.pkl`

### In `mlruns/` directory:
- Complete MLflow experiment tracking
- Model registry
- Metrics and parameters history

---

## üîç View MLflow UI

To view the MLflow tracking UI and explore logged experiments:

```bash
mlflow ui
```

Then open your browser to: `http://localhost:5000`

---

## üìã Configuration

All configuration is managed via `src/config.py` using dataclasses:

```python
@dataclass
class ModelConfig:
    random_state: int = 42
    test_size: float = 0.2
    n_clusters_risk: int = 3
    rf_n_estimators: int = 100
    rf_max_depth: int = 10
```

---

## ‚ú® Key Improvements

1. **Function Naming:** Updated to match final requirements
   - `aggregate_features()` ‚Üí `aggregate_customer_features()`
   - `preprocess_pipeline()` ‚Üí `preprocessing_pipeline()`

2. **MLflow Integration:** Complete experiment tracking
   - Comprehensive parameter logging
   - Detailed metrics tracking
   - Model artifact management
   - Model registry integration

3. **Best Model Selection:** Automatically identifies and logs the best performing model

4. **Feature Importance:** Logs feature importance for Random Forest models

5. **Enhanced Logging:** Detailed console output with progress indicators

---

## üìù Next Steps

1. **View Experiments:** Run `mlflow ui` to explore logged experiments
2. **Model Deployment:** Use MLflow's model serving capabilities
3. **Hyperparameter Tuning:** Implement grid search with MLflow tracking
4. **Model Monitoring:** Set up MLflow model monitoring pipeline

---

## ‚úÖ Validation

Pipeline successfully executed with:
- ‚úÖ All required functions implemented
- ‚úÖ MLflow logging operational
- ‚úÖ Models saved successfully
- ‚úÖ ROC-AUC metrics calculated
- ‚úÖ Best model identified and registered

**Status:** PRODUCTION READY üéâ
